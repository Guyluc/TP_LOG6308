{"cells":[{"cell_type":"markdown","metadata":{"id":"qzCGvuPoHNCS"},"source":["# TP1 -- Approches collaboratives : utilisateur-utilisateur, item-item, et agglomérative\n","\n","\n","Lamia Salhi - 2164386\n","\n","Théo Delbecq - 2161923"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"btcNNBp4HNCU","executionInfo":{"status":"ok","timestamp":1675644038591,"user_tz":-60,"elapsed":464,"user":{"displayName":"Théo Delbecq","userId":"13893417375440016705"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"]},{"cell_type":"markdown","metadata":{"id":"8slkTjthHNCV"},"source":["#### Charger les Données"]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"NlGuLF6kIEjX","executionInfo":{"status":"ok","timestamp":1675404589256,"user_tz":-60,"elapsed":23717,"user":{"displayName":"Théo Delbecq","userId":"13893417375440016705"}},"outputId":"8e500fc0-32c1-4330-88d3-26b82c6d7078"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-bf8242af-0c83-4078-9440-af41320c9f26\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-bf8242af-0c83-4078-9440-af41320c9f26\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving votes.csv to votes.csv\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27KNMVMlHNCV"},"outputs":[],"source":["# votes\n","votes = pd.read_csv('Data/votes.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"8ZtEBM7OHNCW","executionInfo":{"status":"ok","timestamp":1675415020562,"user_tz":-60,"elapsed":160,"user":{"displayName":"Théo Delbecq","userId":"13893417375440016705"}},"outputId":"a26fa682-16bf-452c-e35f-70c4e84f5896"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["item.id  1     2     3     4     5     6     7     8     9     10    ...  \\\n","user.id                                                              ...   \n","1         5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n","2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n","3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n","4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n","5         4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n","...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n","939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN  ...   \n","940       NaN   NaN   NaN   2.0   NaN   NaN   4.0   5.0   3.0   NaN  ...   \n","941       5.0   NaN   NaN   NaN   NaN   NaN   4.0   NaN   NaN   NaN  ...   \n","942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n","943       NaN   5.0   NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN  ...   \n","\n","item.id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n","user.id                                                              \n","1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n","939       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","940       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","941       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","942       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","943       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n","\n","[943 rows x 1682 columns]"],"text/html":["\n","  <div id=\"df-8f2bc334-93f7-4a35-8299-b62b17303fa6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>item.id</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>...</th>\n","      <th>1673</th>\n","      <th>1674</th>\n","      <th>1675</th>\n","      <th>1676</th>\n","      <th>1677</th>\n","      <th>1678</th>\n","      <th>1679</th>\n","      <th>1680</th>\n","      <th>1681</th>\n","      <th>1682</th>\n","    </tr>\n","    <tr>\n","      <th>user.id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>939</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>940</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>941</th>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>942</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>943</th>\n","      <td>NaN</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>943 rows × 1682 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f2bc334-93f7-4a35-8299-b62b17303fa6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8f2bc334-93f7-4a35-8299-b62b17303fa6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8f2bc334-93f7-4a35-8299-b62b17303fa6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":112}],"source":["## Matrice Utilisateur Item\n","MUI = votes.pivot(index=\"user.id\", columns=\"item.id\", values=\"rating\")\n","MUI"]},{"cell_type":"markdown","metadata":{"id":"xAVm_ZOeHNCW"},"source":["## Question 2 - Filtres Collaboratifs\n","\n","Calculez l'erreur des prédictions des approches de filtres collaboratifs item-item et utilisateur-utilisateur. Utilisez le cosinus comme mesure de similarité entre items. Procédez par étape et rapportez, à chaque étape, l'erreur quadratique moyenne et l'erreur absolue moyenne.\n","Répéter pour chacune des deux approches, item-item et utilisateur-utilisateur, les étapes suivantes :"]},{"cell_type":"markdown","source":["### 2.1 Utilitaires"],"metadata":{"id":"tk6d0CZeJIc7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8swiztuHNCW"},"outputs":[],"source":["#Implémentation de fonctions utilitaires pour l'évaluation\n","\n","def RMSE_mat(y_pred, y_true):\n","    return np.sqrt(np.nanmean((y_pred - y_true)**2))\n","\n","def MAE_mat(y_pred, y_true):\n","    return np.nanmean(np.abs(y_pred - y_true))\n","\n","def cos_sim_rows(mat):\n","    \"\"\"\n","    Calcul de la similarité du cosinus entre les lignes d'une même matrice\n","    \"\"\"\n","    norms = np.linalg.norm(mat, axis=1)\n","    norms[norms == 0] = 1 #For the zero division case\n","    return (mat @ mat.T) / (norms[:, np.newaxis] * norms[np.newaxis, :])"]},{"cell_type":"markdown","source":["### 2.2 Traitement\n","\n","\n"],"metadata":{"id":"8HeMd7QpyWEC"}},{"cell_type":"markdown","source":["#### Etape a \n","Prédiction avec tous les utilisateurs/items (sans voisins rapprochés) et sans correction pour biais utilisateur/item. (6 points)"],"metadata":{"id":"Gt-Kx9GdIuXT"}},{"cell_type":"code","source":["def etape_a(mat_train, test = False, mat_test = None, idx_train = None):\n","  \"\"\"\n","  Modèle de prédiction de base par la moyenne pondérée des voisins.\n","\n","  Parameter\n","  ---------\n","  mat_train : np.array\n","      Matrice des données d'entraînement\n","  test : bool\n","      Realisation de l'evaluation sur un ensemble de test fourni\n","  mat_test : np.array\n","      Matrice des données de test\n","  idx_train : np.array\n","      Index des cellules contenant des données d'entraînement\n","\n","  Returns\n","  -------\n","  float64, float64\n","      RMSE et MAE sur la matrice d'entraînement ou celle de test s'il y a lieu\n","  \"\"\"\n","  mat_zeros = np.nan_to_num(mat_train)\n","\n","  W = cos_sim_rows(mat_zeros)\n","\n","  np.fill_diagonal(W, 0)\n","\n","  Kappa = np.abs(W) @ ~np.isnan(mat_train)\n","\n","  Kappa[Kappa == 0] = 1\n","\n","  Preds = (W @ mat_zeros) / Kappa\n","\n","  if test:\n","    Preds[idx_train] = np.nan\n","\n","    return RMSE_mat(Preds, mat_test), MAE_mat(Preds, mat_test)\n","  \n","  else:\n","    return RMSE_mat(Preds, mat_train), MAE_mat(Preds, mat_train)"],"metadata":{"id":"AgwXVRa70Q_o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Etape b \n","Correction pour biais utilisateur/item. Vous pouvez prendre l'ensemble des les valeurs observées dans le calcul des moyennes items et utilisateurs (des précisions sur ce point seront données en classe — voir aussi le bonus en (f)). (4 points)"],"metadata":{"id":"twElOGD0I8Ri"}},{"cell_type":"code","source":["def etape_b(mat_train, test = False, mat_test = None, idx_train = None):\n","  \"\"\"\n","  Modèle de prédiction avec correction par les moyennes des lignes.\n","\n","  Parameter\n","  ---------\n","  mat_train : np.array\n","      Matrice des données d'entraînement\n","  test : bool\n","      Realisation de l'evaluation sur un ensemble de test fourni\n","  mat_test : np.array\n","      Matrice des données de test\n","  idx_train : np.array\n","      Index des cellules contenant des données d'entraînement\n","\n","  Returns\n","  -------\n","  float64, float64, np.array, np.array, np.array\n","      RMSE et MAE sur la matrice d'entraînement ou celle de test s'il y a lieu\n","      Les matrice de poids, de votes centrés et les moyennes sont aussi renvoyées\n","      pour gagner du temps sur les étapes suivantes\n","  \"\"\"\n","  row_means = np.nanmean(mat_train, axis=1)\n","\n","  row_means[np.isnan(row_means)] = 0\n","\n","  R = mat_train - row_means[:, np.newaxis]\n","\n","  R_zeros = np.nan_to_num(R)\n","  \n","  W = cos_sim_rows(R_zeros)\n","\n","  np.fill_diagonal(W, 0)\n","\n","  Kappa = np.abs(W) @ ~np.isnan(mat_train)\n","\n","  Kappa[Kappa == 0] = 1\n","\n","  Preds = (W @ R_zeros) / Kappa + row_means[:, np.newaxis]\n","\n","  if test:\n","    Preds[idx_train] = np.nan\n","\n","    return RMSE_mat(Preds, mat_test), MAE_mat(Preds, mat_test), W, R_zeros, row_means\n","  \n","  else:\n","    return RMSE_mat(Preds, mat_train), MAE_mat(Preds, mat_train), W, R_zeros, row_means"],"metadata":{"id":"t3pOFBPA8kCj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Etape c\n","Ajout de 100 voisins rapprochés (ou le maximum disponible jusqu'à concurrence de 100). Vous pouvez prendre le cosinus ou la distance euclidienne pour les voisins rapprochés. (2 points)"],"metadata":{"id":"_OanjNW-Q-Wd"}},{"cell_type":"code","source":["def etape_c(mat_train, W, R_zeros, row_means, test = False, mat_test = None, idx_train = None):\n","  \"\"\"\n","  Modèle de prédiction avec correction par la proximité des voisins.\n","\n","  Parameter\n","  ---------\n","  mat_train : np.array\n","      Matrice des données d'entraînement\n","  W : np.array\n","      Matrice de poids de l'étape précédente\n","  R_zeros : np.array\n","      Matrice des votes centrés\n","  row_means : np.array\n","      Moyennes des lignes\n","  test : bool\n","      Realisation de l'evaluation sur un ensemble de test fourni\n","  mat_test : np.array\n","      Matrice des données de test\n","  idx_train : np.array\n","      Index des cellules contenant des données d'entraînement\n","\n","  Returns\n","  -------\n","  float64, float64, np.array\n","      RMSE et MAE sur la matrice d'entraînement ou celle de test s'il y a lieu\n","      La matrice de poids modifiées et renvoyée pour les étapes suivantes\n","  \"\"\"\n","\n","  top100 = np.repeat(np.sort(W, axis=1)[:,len(W) - 100][:, np.newaxis], W.shape[1], axis=1)\n","\n","  W[W < top100] = 0\n","\n","  Kappa = np.abs(W) @ ~np.isnan(mat_train)\n","\n","  Kappa[Kappa == 0] = 1\n","\n","  Preds = (W @ R_zeros) / Kappa + row_means[:, np.newaxis]\n","\n","  if test:\n","    Preds[idx_train] = np.nan\n","\n","    return RMSE_mat(Preds, mat_test), MAE_mat(Preds, mat_test), W\n","  \n","  else:\n","    return RMSE_mat(Preds, mat_train), MAE_mat(Preds, mat_train), W"],"metadata":{"id":"rHuPBNf0D-qC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Etape d\n","Correction pour le nombre de votes communs. (2 points)"],"metadata":{"id":"dO5rfZyVQ-qy"}},{"cell_type":"code","source":["def etape_d(mat_train, W, R_zeros, row_means, gamma = 5, test = False, mat_test = None, idx_train = None):\n","  \"\"\"\n","  Modèle de prédiction avec correction par le nombre de vote commun.\n","\n","  Parameter\n","  ---------\n","  mat_train : np.array\n","      Matrice des données d'entraînement\n","  W : np.array\n","      Matrice de poids de l'étape précédente\n","  R_zeros : np.array\n","      Matrice des votes centrés\n","  row_means : np.array\n","      Moyennes des lignes\n","  gamma : int\n","      Seuil pour la correction des votes commun\n","  test : bool\n","      Realisation de l'evaluation sur un ensemble de test fourni\n","  mat_test : np.array\n","      Matrice des données de test\n","  idx_train : np.array\n","      Index des cellules contenant des données d'entraînement\n","\n","  Returns\n","  -------\n","  float64, float64, np.array\n","      RMSE et MAE sur la matrice d'entraînement ou celle de test s'il y a lieu\n","      La matrice de poids modifiées et renvoyée pour les étapes suivantes\n","  \"\"\"\n","\n","  vote_mask = ~np.isnan(mat_train)\n","  nb_common_votes = vote_mask @ vote_mask.T\n","\n","  W = W * (np.maximum(nb_common_votes, gamma) / gamma)\n","\n","  Kappa = np.abs(W) @ ~np.isnan(mat_train)\n","\n","  Kappa[Kappa == 0] = 1\n","\n","  Preds = (W @ R_zeros) / Kappa + row_means[:, np.newaxis]\n","\n","  if test:\n","    Preds[idx_train] = np.nan\n","\n","    return RMSE_mat(Preds, mat_test), MAE_mat(Preds, mat_test), W\n","  \n","  else:\n","    return RMSE_mat(Preds, mat_train), MAE_mat(Preds, mat_train), W"],"metadata":{"id":"qrewsITq9Zbw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Etape e\n","Correction pour le facteur de rareté (fréquence inverse utilisateur). (1 point)"],"metadata":{"id":"YHRnTPQ4Q-3M"}},{"cell_type":"code","source":["def etape_e(mat_train, W, R_zeros, row_means, gamma = 5, test = False, mat_test = None, idx_train = None):\n","  \"\"\"\n","  A l'inverse des précédentes, cette étape n'est pas symétriques en mode user-user et item-item\n","\n","  Pour l'approche item-item, c'est assez naturel. On pondère la matrice de poids par les facteurs IDF car on veut directement avantager les items rares.\n","\n","  Pour l'approche user-user en revanche le coefficient IDF appliqué aux utilisateurs n'a pas forcément de sens car on ne veut pas privilégier les utilisateurs avec le moins de votes différents.\n","  On implémente donc uniquement une solution item-item ici\n","  \"\"\"\n","  IDF = np.log(mat_train.shape[1] / (np.sum(~np.isnan(mat_train), axis=1)) + 1)\n","\n","  W = W * IDF\n","\n","  Kappa = np.abs(W) @ ~np.isnan(mat_train)\n","\n","  Kappa[Kappa == 0] = 1\n","\n","  Preds = (W @ R_zeros) / Kappa + row_means[:, np.newaxis]\n","\n","  if test:\n","    Preds[idx_train] = np.nan\n","\n","    return RMSE_mat(Preds, mat_test), MAE_mat(Preds, mat_test)\n","  \n","  else:\n","    return RMSE_mat(Preds, mat_train), MAE_mat(Preds, mat_train)"],"metadata":{"id":"GGkfBCmZ9bzO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Etape f\n","Un bonus de 2 points sera accordé si, à la question (b), vous évaluez correctement le biais entraîné par l'inclusion de la valeur observée dans le calcul de la moyenne pour cette même valeur prédite. Le maximum au TP demeure cependant de 20/20.\n","\n","\n","----\n","Pour cela on peut évaluer le biais avec une validation croisée leave-one-out qui permet d'avoir la meilleur estimation possible de la performance, sans perte de données tout en excluant la valeur testée du calcul de la moyenne de sa ligne et donc en soustayant le bais informatif de cette intersection entre les données réelles et les informations utilisées pour la prédiction. On compare à l'évaluation biaisée pour connaître le gain exact apporté par ce biais.\n","\n","En pratique, la validation croisée leave-one-out est très longue (estimation 3.5h avec le code ci-dessous) donc on limite le nombre de replis à 1000, ce qui ne donnera pas une évaluation parfaite du biais mais permettra d'avoir une estimation."],"metadata":{"id":"M35Jo68XQ_8N"}},{"cell_type":"code","source":["def etape_f_LOOCV(mat):\n","  \"\"\"\n","  Cette fonction réalise le test non biaisé de l'étape.\n","  Son exécution est longue aussi on tuilise un version avec moins de replis qui donne une évaluation imparfaite mais plus rapide\n","  \"\"\"\n","  list_notna = np.argwhere(~np.isnan(mat))\n","\n","  RMSE = 0 #MAE et RMSE sont équivalente sur une unique prédiction\n","\n","  for x,y in list_notna:\n","    value = mat[x ,y]\n","    mat[x ,y] = np.nan\n","\n","    if np.nansum(mat[x, :]) == 0:\n","\n","      RMSE += value #On prédit 0 s'il est impossible de faire une prédiction car c'était la seule valeur de la ligne, donc la RMSE sur cette unique valeur vaut value (car c'est toujours positif)\n","\n","      mat[x ,y] = value\n","      continue\n","\n","    row_means = np.nanmean(mat, axis=1)\n","\n","    row_means[np.isnan(row_means)] = 0\n","\n","    R = mat - row_means[:, np.newaxis]\n","\n","    R_zeros = np.nan_to_num(R)\n","\n","    norms = np.linalg.norm(mat, axis=1) #Les normes ne peuvent pas être nulles en leave one out dans notre cas car chaque ligne a au moins un élément\n","    W = (mat[x, :] @ mat.T) / (norms[x] * norms)\n","\n","    W[x] = 0\n","\n","    Kappa = np.abs(W) @ ~np.isnan(mat[:, y])\n","\n","    if Kappa == 0 : Kappa = 1\n","\n","    pred = (W @ R_zeros[:, y]) / Kappa + row_means[x]\n","\n","    RMSE += np.abs(pred - value)\n","\n","    mat[x ,y] = value\n","  \n","  return RMSE / len(list_notna)"],"metadata":{"id":"PCCvWLho9C9c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def etape_f(mat, n_folds):\n","  \"\"\"\n","  Etape B avec validation croisée pour une évaluation non biaisée avec une par de données d'entraînement réglable\n","  \"\"\"\n","  \n","  flat_index_notna = np.nonzero(~np.isnan(mat.ravel()))[0]\n","\n","  assert len(flat_index_notna) % n_folds == 0, \"n_folds should exactly divide 100k\"\n","\n","  np.random.shuffle(flat_index_notna)\n","  idx_split = np.split(flat_index_notna, n_folds)\n","\n","  RMSE = 0\n","  MAE = 0\n","  \n","  for i in range(n_folds):\n","    idx_train = np.unravel_index(np.delete(idx_split, i, axis=0).flatten(), mat.shape)\n","    idx_test = np.unravel_index(idx_split[i], mat.shape)\n","    \n","    mat_train = mat.copy()\n","    mat_test = mat.copy()\n","\n","    mat_train[idx_test] = np.nan\n","    mat_test[idx_train] = np.nan\n","\n","    RMSE_fold, MAE_fold, _,_,_ = etape_b(mat_train, test = True, mat_test = mat_test, idx_train = idx_train)\n","    RMSE += RMSE_fold\n","    MAE += MAE_fold\n","\n","  return RMSE / n_folds, MAE / n_folds"],"metadata":{"id":"DEvoUAPdL8TH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Etape g\n","Bonus 2 points : refaites les calculs (a) à (c) mais cette fois avec une validation croisée de 5 replis et comparez les résultats avec les calculs sans validation croisée. Le maximum au TP demeure cependant de 20/20."],"metadata":{"id":"WJqCWGGYTGsa"}},{"cell_type":"code","source":["def etape_g(mat, n_folds=5):\n","  \"\"\"\n","  Etape A à C avec validation croisée\n","  \"\"\"\n","  flat_index_notna = np.nonzero(~np.isnan(mat.ravel()))[0]\n","\n","  assert len(flat_index_notna) % n_folds == 0, \"n_folds should exactly divide 100k\"\n","\n","  np.random.shuffle(flat_index_notna)\n","  idx_split = np.split(flat_index_notna, n_folds)\n","\n","  RMSE_a = 0\n","  MAE_a = 0\n","\n","  RMSE_b = 0\n","  MAE_b = 0\n","\n","  RMSE_c = 0\n","  MAE_c = 0\n","  \n","  for i in range(n_folds):\n","    idx_train = np.unravel_index(np.delete(idx_split, i, axis=0).flatten(), mat.shape)\n","    idx_test = np.unravel_index(idx_split[i], mat.shape)\n","    \n","    mat_train = mat.copy()\n","    mat_test = mat.copy()\n","\n","    mat_train[idx_test] = np.nan\n","    mat_test[idx_train] = np.nan\n","\n","    RMSE_fold, MAE_fold = etape_a(mat_train, test = True, mat_test = mat_test, idx_train = idx_train)\n","    RMSE_a += RMSE_fold\n","    MAE_a += MAE_fold\n","\n","    RMSE_fold, MAE_fold, W, R_zeros, row_means = etape_b(mat_train, test = True, mat_test = mat_test, idx_train = idx_train)\n","    RMSE_b += RMSE_fold\n","    MAE_b += MAE_fold\n","\n","    RMSE_fold, MAE_fold, _ = etape_c(mat_train, W, R_zeros, row_means, test = True, mat_test = mat_test, idx_train = idx_train)\n","    RMSE_c += RMSE_fold\n","    MAE_c += MAE_fold\n","\n","  return RMSE_a / n_folds, MAE_a / n_folds, RMSE_b / n_folds, MAE_b / n_folds, RMSE_c / n_folds, MAE_c / n_folds"],"metadata":{"id":"S33Kf38NTFGT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.3 Résultats et analyse"],"metadata":{"id":"kHdmGHopASxc"}},{"cell_type":"code","source":["def traitement(mat, approche, n_folds_bias_test):\n","  \"\"\"\n","  Réalisation des tests sur l'ensemble des étapes selon l'approche voulue\n","  \"\"\"\n","  if approche == 'user':\n","    MUI_mat = mat.to_numpy().copy()\n","    RMSE_list, MAE_list = [], []\n","\n","    RMSE, MAE = etape_a(MUI_mat)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE, MAE, W, R_zeros, row_means = etape_b(MUI_mat)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE, MAE, W = etape_c(MUI_mat, W, R_zeros, row_means)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE, MAE, W = etape_d(MUI_mat, W, R_zeros, row_means)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    #Pas d'étape e en user-user\n","    RMSE_list.append(np.nan), MAE_list.append(np.nan)\n","    RMSE, MAE = etape_f(MUI_mat, n_folds_bias_test)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE_a, MAE_a, RMSE_b, MAE_b, RMSE_c, MAE_c = etape_g(MUI_mat)\n","    RMSE_list.extend((RMSE_a, RMSE_b, RMSE_c)), MAE_list.extend((MAE_a, MAE_b, MAE_c))\n","\n","    return np.array([RMSE_list, MAE_list])\n","\n","  elif approche == 'item':\n","    MIU_mat = mat.to_numpy().T.copy()\n","    RMSE_list, MAE_list = [], []\n","\n","    RMSE, MAE = etape_a(MIU_mat)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE, MAE, W, R_zeros, row_means = etape_b(MIU_mat)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE, MAE, W = etape_c(MIU_mat, W, R_zeros, row_means)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE, MAE, W = etape_d(MIU_mat, W, R_zeros, row_means)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE, MAE = etape_e(MIU_mat, W, R_zeros, row_means)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE, MAE = etape_f(MIU_mat, n_folds_bias_test)\n","    RMSE_list.append(RMSE), MAE_list.append(MAE)\n","    RMSE_a, MAE_a, RMSE_b, MAE_b, RMSE_c, MAE_c = etape_g(MIU_mat)\n","    RMSE_list.extend((RMSE_a, RMSE_b, RMSE_c)), MAE_list.extend((MAE_a, MAE_b, MAE_c))\n","\n","    return np.array([RMSE_list, MAE_list])"],"metadata":{"id":"ZtN78NtnzHTX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def display_tab(results_uu, results_ii):\n","  \"\"\"\n","  Tableau d'affichage des résulats de totues les étapes pour les deux approches\n","  \"\"\"\n","  results_tab = pd.DataFrame(np.vstack((results_uu[0], results_ii[0], results_uu[1], results_ii[1])), columns=['base', 'mean', 'nearest neighbours', 'common votes', 'IDF', 'mean unbiased', 'base CV5', 'mean CV5', 'nearest neigbours CV5'], index=['RMSE user-user', 'RMSE item-item', 'MAE user-user', 'MAE item_item'])\n","  display(results_tab)"],"metadata":{"id":"UrOk5VmpYzjn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Traitement de toutes les étapes en approche utilisateurs-utilisateurs\n","#n_folds_bias_test influe sur le temps d'execution, avec 1000 l'execution prends une dizaine de minutes. Réduire pour une execution plus rapide\n","results_uu = traitement(MUI, 'user', n_folds_bias_test = 1000)\n","\n","#Traitement de toutes les étapes en approche items-items\n","results_ii = traitement(MUI, 'item', n_folds_bias_test = 1000)\n","\n","display_tab(results_uu, results_ii)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"Z_vmW6ieeiNB","executionInfo":{"status":"ok","timestamp":1675415895352,"user_tz":-60,"elapsed":874793,"user":{"displayName":"Théo Delbecq","userId":"13893417375440016705"}},"outputId":"7afb0b77-0aaa-49e4-ff78-ccdb58fe1963"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-115-8725f25d0d03>:2: RuntimeWarning: Mean of empty slice\n","  row_means = np.nanmean(mat_train, axis=1)\n"]},{"output_type":"display_data","data":{"text/plain":["                    base      mean  nearest neighbours  common votes  \\\n","RMSE user-user  1.015850  0.803798            0.803774      0.803774   \n","RMSE item-item  1.012081  0.748296            0.734176      0.734176   \n","MAE user-user   0.808550  0.628008            0.625026      0.625026   \n","MAE item_item   0.805072  0.587617            0.571074      0.571074   \n","\n","                     IDF  mean unbiased  base CV5  mean CV5  \\\n","RMSE user-user       NaN       0.926474  1.021160  0.939272   \n","RMSE item-item  0.727377       0.926649  1.018446  0.942490   \n","MAE user-user        NaN       0.730806  0.812796  0.739266   \n","MAE item_item   0.565593       0.730669  0.809063  0.740813   \n","\n","                nearest neigbours CV5  \n","RMSE user-user               0.952457  \n","RMSE item-item               0.949042  \n","MAE user-user                0.742983  \n","MAE item_item                0.735346  "],"text/html":["\n","  <div id=\"df-c4b09aed-7f89-471a-a5a5-f0b6857a478c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>base</th>\n","      <th>mean</th>\n","      <th>nearest neighbours</th>\n","      <th>common votes</th>\n","      <th>IDF</th>\n","      <th>mean unbiased</th>\n","      <th>base CV5</th>\n","      <th>mean CV5</th>\n","      <th>nearest neigbours CV5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>RMSE user-user</th>\n","      <td>1.015850</td>\n","      <td>0.803798</td>\n","      <td>0.803774</td>\n","      <td>0.803774</td>\n","      <td>NaN</td>\n","      <td>0.926474</td>\n","      <td>1.021160</td>\n","      <td>0.939272</td>\n","      <td>0.952457</td>\n","    </tr>\n","    <tr>\n","      <th>RMSE item-item</th>\n","      <td>1.012081</td>\n","      <td>0.748296</td>\n","      <td>0.734176</td>\n","      <td>0.734176</td>\n","      <td>0.727377</td>\n","      <td>0.926649</td>\n","      <td>1.018446</td>\n","      <td>0.942490</td>\n","      <td>0.949042</td>\n","    </tr>\n","    <tr>\n","      <th>MAE user-user</th>\n","      <td>0.808550</td>\n","      <td>0.628008</td>\n","      <td>0.625026</td>\n","      <td>0.625026</td>\n","      <td>NaN</td>\n","      <td>0.730806</td>\n","      <td>0.812796</td>\n","      <td>0.739266</td>\n","      <td>0.742983</td>\n","    </tr>\n","    <tr>\n","      <th>MAE item_item</th>\n","      <td>0.805072</td>\n","      <td>0.587617</td>\n","      <td>0.571074</td>\n","      <td>0.571074</td>\n","      <td>0.565593</td>\n","      <td>0.730669</td>\n","      <td>0.809063</td>\n","      <td>0.740813</td>\n","      <td>0.735346</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4b09aed-7f89-471a-a5a5-f0b6857a478c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c4b09aed-7f89-471a-a5a5-f0b6857a478c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c4b09aed-7f89-471a-a5a5-f0b6857a478c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["Analyse des résultats et réponses :\n","\n","Les résultats obtenus avec la méthode de base sont proches de notre baseline avec moyenne par item (sans cross validation) et un peu plus faible que notre meilleure baseline par valeur attendue (RMSE : 0.966809 et MAE : 0.782583). L'estimation de base étant une moyenne pondérée des voisins elle ne contient pas de régularisation par rapport aux informations de la ligne donc il n'est pas surprenant que les résultats soient faibles. On dépasse la baseline assez fortement grâce au gain important par l'ajout de la correction des moyennes Ensuite, les autres composantes apportent un gain plus modéré, d'environ 0.01 poitn d'erreur, voir nul pour l'amplification des utilisateurs avec votes communs.\n","\n","L'estimation du biais induit par l'ajout de la valeur réelle dans la moyenne utilisée pour la prédiction à l'étape B est faite par une validation croisée à 1000 replis. L'estimation n'est pas parfaite (Il faudrait un leave-one-out pour cela mais c'est assez long à tourner) et une perte d'information susbsite liée à la diminution de la taille du dataset d'entraînement mais on peut estimer qu'elle reste raisonnable avec 1000 replis (1% des données retirées). Cette estimation exhibe une différence de RMSE de 0.12 à 0.18 (selon l'approche u-u ou i-i) et une différence de MAE 0.11 à 0.15 soit un gain d'environ 20% sur les erreurs uniquement due à un biais d'estimation.\n","\n","On observe aussi naturellement une erreur plus grand avec la validation croisée sur les étapes A à C du fait du nombre de données réduit et du retrait du biais.\n","\n","Si l'on compare les approches utilisateurs-utilisateurs et items-items on constate aussi que l'approche i-i est plus performante de manière assez notable dans toutes les évaluations biaisées après l'ajoute de la correction par la moyenne mais que ce gain est retiré avec une évaluation non biaisée. On peut penser que le fait qu'il y ait moins d'utilisateurs que d'items rend l'inclusion d'un biais plus simple dans une moyenne par une valeur ou aussi que les moyennes sont moins informatives au niveau utilisateur du fait d'une variance interne plus élevée.\n"],"metadata":{"id":"m6lE6ILhhWY9"}}],"metadata":{"interpreter":{"hash":"66befc373c9148fff75f5d0bd6c9fa3931c2bc3dd4cc8bea8360c4a1f9ef5ddb"},"kernelspec":{"display_name":"Python 3.9.5 ('envtp1': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}